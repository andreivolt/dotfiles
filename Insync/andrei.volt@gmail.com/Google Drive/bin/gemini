#!/usr/bin/env -S pipx run
# /// script
# dependencies = [
#    "google-generativeai>=0.1.0",
#    "python-magic>=0.4.27",
#    "pylibmagic>=0.1.0",
# ]
# ///

import os
import sys
import argparse
import json
import tempfile
import time
import google.generativeai as genai
import pylibmagic
import magic
from urllib.parse import urlparse

def configure_genai(api_key_env_var='GEMINI_API_KEY'):
    api_key = os.getenv(api_key_env_var)
    if not api_key:
        print(f"Error: {api_key_env_var} environment variable is required")
        sys.exit(1)
    genai.configure(api_key=api_key)

def upload_file_and_wait(file_path):
    try:
        mime_type = magic.from_file(file_path, mime=True)
        if mime_type == 'application/octet-stream':
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    f.read()
                mime_type = 'text/plain'
            except:
                pass
        uploaded_file = genai.upload_file(file_path, mime_type=mime_type)
        while True:
            file_info = genai.get_file(uploaded_file.name)
            if file_info.state.name == 'ACTIVE':
                break
            time.sleep(1)
        return uploaded_file
    except Exception as e:
        print(f"Error uploading file '{file_path}': {e}")
        sys.exit(1)

def handle_stdin():
    if not sys.stdin.isatty():
        try:
            with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                tmp_file.write(sys.stdin.buffer.read())
                tmp_path = tmp_file.name
            mime_type = magic.from_file(tmp_path, mime=True)
            if mime_type == 'application/octet-stream':
                mime_type = 'text/plain'
            uploaded_file = genai.upload_file(tmp_path, mime_type=mime_type)
            while True:
                file_info = genai.get_file(uploaded_file.name)
                if file_info.state.name == 'ACTIVE':
                    break
                time.sleep(1)
            os.unlink(tmp_path)
            return uploaded_file
        except Exception as e:
            print(f"Error handling standard input: {e}")
            sys.exit(1)
    return None

def is_youtube_uri(uri):
    parsed = urlparse(uri)
    if parsed.hostname in ['www.youtube.com', 'youtube.com', 'youtu.be']:
        return True
    return False

def generate_content(prompt: str, schema_path: str = None, model: str = 'gemini-1.5-flash-8b', attach=None, stdin_file=None, raw=False, **generation_params):
    try:
        content_list = [prompt]
        if stdin_file:
            content_list.append(stdin_file)
        if attach:
            for attachment in attach:
                if attachment.startswith(('http://', 'https://', 'gs://')):
                    if is_youtube_uri(attachment):
                        part = genai.Part.from_uri(
                            uri=attachment,
                            mime_type="video/mp4"
                        )
                    else:
                        # For gs:// URIs, determine MIME type using a temporary method
                        # Since magic cannot handle gs:// URIs directly, you might need to extract the file extension
                        parsed = urlparse(attachment)
                        file_path = parsed.path
                        _, ext = os.path.splitext(file_path)
                        mime_type = magic.Magic(mime=True).from_buffer(ext.encode())
                        if not mime_type:
                            print(f"Error: Could not determine MIME type for URI '{attachment}'")
                            sys.exit(1)
                        part = genai.Part.from_uri(
                            uri=attachment,
                            mime_type=mime_type
                        )
                    content_list.append(part)
                else:
                    # Assume it's a local file
                    if os.path.isfile(attachment):
                        uploaded_file = upload_file_and_wait(attachment)
                        content_list.append(uploaded_file)
                    else:
                        print(f"Error: Attachment '{attachment}' is neither a valid URI nor a local file.")
                        sys.exit(1)
        if schema_path:
            with open(schema_path, 'r') as f:
                schema = json.load(f)
            generation_params['response_schema'] = schema
        generation_config = genai.GenerationConfig(**generation_params)
        model_instance = genai.GenerativeModel(model)
        response = model_instance.generate_content(
            content_list,
            generation_config=generation_config,
            request_options={"timeout": None}
        )
        if raw:
            print(response)
        else:
            for candidate in response.candidates:
                print(candidate.content.parts[0].text)
    except FileNotFoundError:
        print(f"Error: Schema file '{schema_path}' not found.")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"Error: Schema file '{schema_path}' is not valid JSON.")
        sys.exit(1)
    except Exception as e:
        print(f"Error during content generation: {e}")
        sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description="Generate text using the Gemini API")
    parser.add_argument('prompt', type=str, help='Prompt to be used')
    parser.add_argument('--pro', action='store_true', help='Use the pro version of the Gemini model')
    parser.add_argument('--attach', nargs='*', help='List of file paths or URIs to attach')
    parser.add_argument('--schema', type=str, help='Path to JSON schema file')
    parser.add_argument('--raw', action='store_true', help='Print raw response')
    parser.add_argument('--temperature', type=float, help='Sampling temperature')
    parser.add_argument('--top_p', type=float, help='Top-p sampling')
    parser.add_argument('--top_k', type=int, help='Top-k sampling')
    parser.add_argument('--candidate_count', type=int, help='Number of response variations to return')
    parser.add_argument('--max_output_tokens', type=int, help='Maximum number of output tokens')
    parser.add_argument('--stop_sequences', nargs='*', help='Stop sequences')
    parser.add_argument('--presence_penalty', type=float, help='Presence penalty')
    parser.add_argument('--frequency_penalty', type=float, help='Frequency penalty')
    parser.add_argument('--response_mime_type', type=str, choices=['application/json', 'text/plain', 'text/x.enum'], help='Response MIME type')
    parser.add_argument('--seed', type=int, help='Seed for deterministic responses')
    parser.add_argument('--response_logprobs', action='store_true', help='Return log probabilities of the tokens')
    parser.add_argument('--logprobs', type=int, help='Number of top candidates to return logprobs for (1-5)')
    args = parser.parse_args()

    configure_genai()
    stdin_file = handle_stdin()
    generation_params = {}
    if args.temperature is not None:
        generation_params['temperature'] = args.temperature
    if args.top_p is not None:
        generation_params['top_p'] = args.top_p
    if args.top_k is not None:
        generation_params['top_k'] = args.top_k
    if args.candidate_count is not None:
        generation_params['candidate_count'] = args.candidate_count
    if args.max_output_tokens is not None:
        generation_params['max_output_tokens'] = args.max_output_tokens
    if args.stop_sequences is not None:
        generation_params['stop_sequences'] = args.stop_sequences
    if args.presence_penalty is not None:
        generation_params['presence_penalty'] = args.presence_penalty
    if args.frequency_penalty is not None:
        generation_params['frequency_penalty'] = args.frequency_penalty
    if args.response_mime_type is not None:
        generation_params['response_mime_type'] = args.response_mime_type
    if args.seed is not None:
        generation_params['seed'] = args.seed
    if args.response_logprobs:
        generation_params['response_logprobs'] = True
    if args.logprobs is not None:
        generation_params['logprobs'] = args.logprobs

    if args.pro:
        selected_model = 'gemini-1.5-pro'
    else:
        selected_model = 'gemini-1.5-flash-8b'

    generate_content(
        prompt=args.prompt,
        schema_path=args.schema,
        model=selected_model,
        attach=args.attach,
        stdin_file=stdin_file,
        raw=args.raw,
        **generation_params
    )

if __name__ == "__main__":
    main()
