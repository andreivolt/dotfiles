#!/usr/bin/env -S rust-script
//! ```cargo
//! [dependencies]
//! tokio = { version = "1.0", features = ["full"] }
//! clap = { version = "4.0", features = ["derive"] }
//! serde_json = "1.0"
//! serde = { version = "1.0", features = ["derive"] }
//! warp = "0.3"
//! reqwest = { version = "0.11", features = ["json"] }
//! uuid = { version = "1.0", features = ["v4"] }
//! dirs = "5.0"
//! anyhow = "1.0"
//! futures = "0.3"
//! local-ip-address = "0.6"
//! tokio-tungstenite = "0.20"
//! futures-util = "0.3"
//! rust_cast = "0.19"
//! cpal = "0.15"
//! ```

use std::sync::Arc;
use std::path::PathBuf;
use std::process::{Command, Stdio};
use std::io::{self, Read, Write};
use std::time::Duration;

use tokio::sync::{Mutex, broadcast};
use clap::Parser;
use serde::{Deserialize, Serialize};
use warp::Filter;
use warp::hyper::{Body, Response};
use futures_util::{SinkExt, StreamExt};
use anyhow::{Result, Context};
use local_ip_address;
use std::sync::mpsc;
use rust_cast::channels::media::{Media, StreamType};
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use cpal::SampleFormat;

#[derive(Parser)]
#[command(name = "chromecast-broadcast")]
#[command(about = "Broadcast audio to Chromecast devices")]
struct Args {
    /// Audio file to broadcast
    #[arg(value_name = "FILE")]
    file: Option<PathBuf>,

    /// Chromecast speaker name
    #[arg(short, long)]
    speaker: Option<String>,

    /// Record live audio from microphone
    #[arg(long)]
    live: bool,

    /// Start web interface
    #[arg(long)]
    web: bool,

    /// Port for web interface
    #[arg(long, default_value = "8080")]
    port: u16,

    /// List available Chromecast devices
    #[arg(long)]
    list: bool,

    /// Force device discovery (ignore cache)
    #[arg(long)]
    force: bool,
}

#[derive(Serialize, Deserialize, Clone)]
struct ChromecastDevice {
    name: String,
    ip: String,
    port: u16,
    device_id: String,
}

#[derive(Serialize, Deserialize)]
struct DeviceCache {
    devices: Vec<ChromecastDevice>,
    timestamp: u64,
}

#[derive(Serialize, Deserialize, Clone)]
#[serde(tag = "type")]
enum WebSocketMessage {
    #[serde(rename = "discover_devices")]
    DiscoverDevices,
    #[serde(rename = "devices_found")]
    DevicesFound { devices: Vec<ChromecastDevice> },
    #[serde(rename = "cast_audio")]
    CastAudio { device_name: String, audio_url: String },
    #[serde(rename = "cast_status")]
    CastStatus { success: bool, message: String },
    #[serde(rename = "start_recording")]
    StartRecording { device_name: String },
    #[serde(rename = "stop_recording")]
    StopRecording,
    #[serde(rename = "recording_status")]
    RecordingStatus { recording: bool, message: String },
    #[serde(rename = "error")]
    Error { message: String },
}


struct ChromecastBroadcaster {
    device_cache: Arc<Mutex<Option<DeviceCache>>>,
    cache_path: PathBuf,
    websocket_tx: broadcast::Sender<WebSocketMessage>,
}

impl ChromecastBroadcaster {
    fn new() -> Self {
        let cache_path = dirs::cache_dir()
            .unwrap_or_else(|| PathBuf::from("/tmp"))
            .join("chromecast_devices.json");

        let (websocket_tx, _) = broadcast::channel(100);

        Self {
            device_cache: Arc::new(Mutex::new(None)),
            cache_path,
            websocket_tx,
        }
    }

    async fn discover_devices(&self, force: bool) -> Result<Vec<ChromecastDevice>> {
        if !force {
            if let Ok(cache) = self.load_cache().await {
                let now = std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)?
                    .as_secs();

                if now - cache.timestamp < 300 { // 5 minutes
                    return Ok(cache.devices);
                }
            }
        }

        let mut devices = Vec::new();

        // Use system discovery tools since rust_cast doesn't have async discovery
        let discovery_result = Command::new("sh")
            .args([
                "-c",
                "timeout 3 dns-sd -B _googlecast._tcp 2>&1 || timeout 3 avahi-browse -t -r _googlecast._tcp 2>&1 || echo 'No discovery tools available'",
            ])
            .output();

        match discovery_result {
            Ok(output) => {
                let output_str = String::from_utf8_lossy(&output.stdout);


                devices = self.parse_discovery_output(&output_str).await;

                if devices.is_empty() {
                    eprintln!("No Chromecast devices found. Make sure devices are on the same network.");
                }
            }
            Err(e) => {
                eprintln!("Failed to discover devices: {}. Install dns-sd (macOS) or avahi-utils (Linux)", e);
            }
        }

        // Cache the discovered devices
        let cache = DeviceCache {
            devices: devices.clone(),
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)?
                .as_secs(),
        };

        self.save_cache(&cache).await?;
        *self.device_cache.lock().await = Some(cache);

        Ok(devices)
    }


    async fn parse_discovery_output(&self, output: &str) -> Vec<ChromecastDevice> {
        let mut devices = Vec::new();

        // Parse dns-sd output format
        for line in output.lines() {
            if line.contains("_googlecast._tcp") && line.contains("Add") {
                // dns-sd format: "timestamp Add flags if domain service instance_name"
                let parts: Vec<&str> = line.split_whitespace().collect();
                if parts.len() >= 7 {
                    let instance_name = parts.last().map_or("", |v| v);

                    // Resolve the friendly name from the TXT record
                    let friendly_name = self.resolve_friendly_name(instance_name).await;

                    // Resolve the actual hostname from dns-sd
                    let hostname = self.resolve_hostname(instance_name).await;

                    devices.push(ChromecastDevice {
                        name: friendly_name,
                        ip: hostname,
                        port: 8009,
                        device_id: uuid::Uuid::new_v4().to_string(),
                    });
                }
            }
        }

        devices
    }


    async fn resolve_hostname(&self, instance_name: &str) -> String {
        let resolve_cmd = format!("timeout 1 dns-sd -L '{}' _googlecast._tcp local 2>&1", instance_name);

        match Command::new("sh").args(["-c", &resolve_cmd]).output() {
            Ok(output) => {
                let stderr_str = String::from_utf8_lossy(&output.stderr);
                let stdout_str = String::from_utf8_lossy(&output.stdout);
                let combined = format!("{}\n{}", stdout_str, stderr_str);

                // Look for "can be reached at" line
                for line in combined.lines() {
                    if line.contains("can be reached at") {
                        if let Some(at_pos) = line.find(" at ") {
                            let rest = &line[at_pos + 4..];
                            if let Some(colon_pos) = rest.find(':') {
                                let hostname = rest[..colon_pos].trim_end_matches('.');
                                return hostname.to_string();
                            }
                        }
                    }
                }

                // Fallback to instance name based hostname
                format!("{}.local", instance_name.to_lowercase())
            }
            Err(_) => {
                format!("{}.local", instance_name.to_lowercase())
            }
        }
    }

    async fn resolve_friendly_name(&self, instance_name: &str) -> String {
        // Use timeout command to limit dns-sd execution time
        let resolve_cmd = format!("timeout 1 dns-sd -L '{}' _googlecast._tcp local 2>&1 | grep fn=", instance_name);

        match Command::new("sh").args(["-c", &resolve_cmd]).output() {
            Ok(output) => {
                let output_str = String::from_utf8_lossy(&output.stdout);

                // Look for fn= field in the TXT record
                for line in output_str.lines() {
                    if let Some(fn_start) = line.find("fn=") {
                        let fn_part = &line[fn_start + 3..];
                        // Find the end of the fn field (next space)
                        let friendly_name = if let Some(space_pos) = fn_part.find(' ') {
                            &fn_part[..space_pos]
                        } else {
                            fn_part
                        };

                        // Unescape backslash-escaped spaces and other characters
                        return friendly_name.replace("\\ ", " ").replace("\\", "");
                    }
                }

                // If no fn= found, use instance name as fallback
                instance_name.to_string()
            }
            Err(_) => {
                // If resolution fails, use instance name
                instance_name.to_string()
            }
        }
    }

    async fn load_cache(&self) -> Result<DeviceCache> {
        let content = tokio::fs::read_to_string(&self.cache_path).await?;
        let cache: DeviceCache = serde_json::from_str(&content)?;
        Ok(cache)
    }

    async fn save_cache(&self, cache: &DeviceCache) -> Result<()> {
        let content = serde_json::to_string_pretty(cache)?;
        if let Some(parent) = self.cache_path.parent() {
            tokio::fs::create_dir_all(parent).await?;
        }
        tokio::fs::write(&self.cache_path, content).await?;
        Ok(())
    }

    async fn find_device(&self, speaker_name: &str) -> Result<ChromecastDevice> {
        let devices = self.discover_devices(false).await?;

        devices.into_iter()
            .find(|d| d.name.to_lowercase().contains(&speaker_name.to_lowercase()))
            .context("Device not found")
    }


    async fn cast_audio(&self, device: &ChromecastDevice, audio_url: &str) -> Result<()> {
        println!("Casting {} to {}", audio_url, device.name);

        // Connect using hostname instead of IP if needed
        let mut connection_device = device.clone();

        // If the hostname doesn't work, try to resolve to IP
        if device.ip.contains(".local") {
            // Try to resolve the mDNS hostname to an IP address
            if let Ok(resolved_ip) = self.resolve_hostname_to_ip(&device.ip).await {
                connection_device.ip = resolved_ip;
                println!("Resolved {} to {}", device.ip, connection_device.ip);
            }
        }

        // Connect without host verification to avoid SSL certificate issues
        println!("Connecting to Chromecast without host verification...");
        let cast_device = match rust_cast::CastDevice::connect_without_host_verification(&connection_device.ip, connection_device.port) {
            Ok(device) => {
                println!("Connected to Chromecast: {}", connection_device.name);
                device
            }
            Err(e) => {
                anyhow::bail!("Failed to connect to Chromecast: {}", e);
            }
        };

        // CRITICAL: Connect to the default receiver first (like the working example)
        println!("Connecting to default receiver...");
        match cast_device.connection.connect("receiver-0".to_string()) {
            Ok(_) => {
                println!("Connected to default receiver");
            }
            Err(e) => {
                anyhow::bail!("Failed to connect to default receiver: {}", e);
            }
        }


        // Skip connection test and proceed directly to app launch
        println!("Proceeding to app launch...");

        // Send heartbeat to ensure connection is alive
        println!("Sending heartbeat to ensure connection...");
        match cast_device.heartbeat.ping() {
            Ok(_) => {
                println!("Heartbeat successful - connection is alive");
            }
            Err(e) => {
                eprintln!("Heartbeat failed: {}", e);
                anyhow::bail!("Connection lost: {}", e);
            }
        }

        // Launch the default media receiver app (like Python version does)
        println!("Launching default media receiver app...");
        use rust_cast::channels::receiver::CastDeviceApp;
        let app = CastDeviceApp::DefaultMediaReceiver;
        
        let app_response = match cast_device.receiver.launch_app(&app) {
            Ok(response) => {
                println!("Successfully launched media receiver app");
                println!("App response: {:?}", response);
                response
            }
            Err(e) => {
                eprintln!("Failed to launch media receiver: {}", e);
                anyhow::bail!("Failed to launch media receiver: {}", e);
            }
        };

        // CRITICAL: Connect to the app's transport ID (like the working example)
        println!("Connecting to app transport ID: {}", app_response.transport_id);
        match cast_device.connection.connect(app_response.transport_id.clone()) {
            Ok(_) => {
                println!("Connected to app transport");
            }
            Err(e) => {
                anyhow::bail!("Failed to connect to app transport: {}", e);
            }
        }

        // App should be ready immediately after successful launch

        // Create media object for live streaming
        let media = Media {
            content_id: audio_url.to_string(),
            stream_type: StreamType::Live,
            content_type: "audio/wav".to_string(),
            metadata: None,
            duration: None,
        };

        // Load media using the app session info
        println!("Loading media to launched app...");
        let destination = &app_response.transport_id;
        let session_id = if app_response.session_id.is_empty() { 
            "0".to_string() 
        } else { 
            app_response.session_id.clone() 
        };
        
        match cast_device.media.load(destination, &session_id, &media) {
            Ok(load_response) => {
                println!("Media loaded successfully");
                println!("Load response: {:?}", load_response);
                
                // Get the media session ID from the load response
                let media_session_id = if let Some(entry) = load_response.entries.first() {
                    entry.media_session_id
                } else {
                    anyhow::bail!("No media session found in load response");
                };
                
                println!("Using media session ID: {}", media_session_id);
                
                // Media should be ready immediately after load
                
                // Play the media using the correct media session ID
                println!("Starting playback...");
                match cast_device.media.play(destination, media_session_id) {
                    Ok(play_response) => {
                        println!("Successfully started playing on {}", device.name);
                        println!("Play response: {:?}", play_response);
                    }
                    Err(e) => {
                        eprintln!("Failed to start playback: {}", e);
                        anyhow::bail!("Failed to start playback: {}", e);
                    }
                }
            }
            Err(e) => {
                eprintln!("Failed to load media: {}", e);
                anyhow::bail!("Failed to load media: {}", e);
            }
        }

        Ok(())
    }

    async fn resolve_hostname_to_ip(&self, hostname: &str) -> Result<String> {
        use std::net::{ToSocketAddrs, IpAddr};

        // Try to resolve the hostname to an IPv4 address
        let socket_addrs: Vec<_> = format!("{}:8009", hostname)
            .to_socket_addrs()?
            .collect();

        // Prefer IPv4 addresses
        for addr in &socket_addrs {
            if let IpAddr::V4(ipv4) = addr.ip() {
                return Ok(ipv4.to_string());
            }
        }

        // Fall back to first address if no IPv4 found
        socket_addrs
            .first()
            .map(|addr| addr.ip().to_string())
            .context("No addresses found")
    }

    async fn create_streaming_server(&self, server_port: u16) -> Result<(mpsc::Sender<Vec<u8>>, u16, tokio::task::JoinHandle<()>)> {
        let (audio_tx, audio_rx) = mpsc::channel::<Vec<u8>>();
        let audio_rx = Arc::new(Mutex::new(audio_rx));

        let stream_route = warp::path("stream.wav")
            .and(warp::get())
            .map({
                let audio_rx = Arc::clone(&audio_rx);
                move || {
                    let audio_rx = Arc::clone(&audio_rx);
                    
                    // Create a response that streams audio chunks
                    let (mut tx, body) = Body::channel();
                    
                    tokio::spawn(async move {
                        let mut total_sent = 0;
                        let mut initial_buffer = Vec::new();
                        
                        // Wait for initial buffer to be ready
                        loop {
                            let chunk = {
                                let rx_guard = audio_rx.lock().await;
                                match rx_guard.try_recv() {
                                    Ok(data) => Some(data),
                                    Err(mpsc::TryRecvError::Empty) => {
                                        drop(rx_guard);
                                        tokio::time::sleep(Duration::from_millis(10)).await;
                                        continue;
                                    }
                                    Err(mpsc::TryRecvError::Disconnected) => None,
                                }
                            };
                            
                            if let Some(chunk) = chunk {
                                initial_buffer.extend_from_slice(&chunk);
                                
                                // Send the chunk immediately
                                total_sent += chunk.len();
                                if tx.send_data(chunk.into()).await.is_err() {
                                    break;
                                }
                                
                                // Continue streaming remaining chunks
                                loop {
                                    let next_chunk = {
                                        let rx_guard = audio_rx.lock().await;
                                        match rx_guard.try_recv() {
                                            Ok(data) => Some(data),
                                            Err(mpsc::TryRecvError::Empty) => {
                                                drop(rx_guard);
                                                tokio::time::sleep(Duration::from_millis(10)).await;
                                                continue;
                                            }
                                            Err(mpsc::TryRecvError::Disconnected) => None,
                                        }
                                    };
                                    
                                    if let Some(chunk) = next_chunk {
                                        total_sent += chunk.len();
                                        if tx.send_data(chunk.into()).await.is_err() {
                                            break;
                                        }
                                    } else {
                                        break;
                                    }
                                }
                                break;
                            } else {
                                break;
                            }
                        }
                        println!("Stream ended, total bytes sent: {}", total_sent);
                    });
                    
                    Response::builder()
                        .header("content-type", "audio/wav")
                        .header("cache-control", "no-cache")
                        .header("access-control-allow-origin", "*")
                        .body(body)
                        .unwrap()
                }
            });

        let (addr_tx, addr_rx) = tokio::sync::oneshot::channel();
        let server_handle = tokio::spawn(async move {
            let server = warp::serve(stream_route);
            let (addr, server_fut) = server.bind_ephemeral(([0, 0, 0, 0], server_port));
            let actual_port = addr.port();
            println!("Starting streaming server on port {}", actual_port);
            let _ = addr_tx.send(actual_port);
            server_fut.await;
        });

        // Wait for server to get its port assignment
        let actual_port = addr_rx.await.context("Failed to get server port")?;

        // Server starts immediately

        Ok((audio_tx, actual_port, server_handle))
    }

    fn start_audio_recording(&self, audio_tx: mpsc::Sender<Vec<u8>>) -> Result<()> {
        let host = cpal::default_host();
        let device = host.default_input_device().context("No default input device available")?;
        
        let config = device.default_input_config().context("Failed to get default input config")?;
        println!("Recording with config: {:?}", config);

        let sample_rate = config.sample_rate().0;
        let channels = config.channels();
        
        // WAV header for 44.1kHz, 16-bit, stereo, streaming (unknown length)
        let wav_header = Self::create_wav_header(44100, 2, 0xFFFFFFFF); // Use max length for streaming
        
        // Send WAV header first
        audio_tx.send(wav_header).context("Failed to send WAV header")?;

        let audio_tx_clone = audio_tx.clone();

        let stream = match config.sample_format() {
            SampleFormat::F32 => {
                device.build_input_stream(
                    &config.into(),
                    move |data: &[f32], _: &cpal::InputCallbackInfo| {
                        // Convert f32 samples to i16 PCM
                        let mut pcm_data = Vec::with_capacity(data.len() * 2);
                        
                        for &sample in data {
                            // Convert f32 to i16
                            let sample_i16 = (sample.clamp(-1.0, 1.0) * i16::MAX as f32) as i16;
                            pcm_data.extend_from_slice(&sample_i16.to_le_bytes());
                        }
                        
                        // Handle channel conversion if needed
                        if channels == 1 {
                            // Duplicate mono to stereo
                            let mut stereo_data = Vec::with_capacity(pcm_data.len() * 2);
                            for chunk in pcm_data.chunks(2) {
                                stereo_data.extend_from_slice(chunk); // Left
                                stereo_data.extend_from_slice(chunk); // Right
                            }
                            let _ = audio_tx_clone.send(stereo_data);
                        } else {
                            let _ = audio_tx_clone.send(pcm_data);
                        }
                    },
                    |err| eprintln!("Audio input error: {}", err),
                    None,
                )?
            }
            SampleFormat::I16 => {
                device.build_input_stream(
                    &config.into(),
                    move |data: &[i16], _: &cpal::InputCallbackInfo| {
                        // Convert i16 samples to bytes
                        let mut pcm_data = Vec::with_capacity(data.len() * 2);
                        
                        for &sample in data {
                            pcm_data.extend_from_slice(&sample.to_le_bytes());
                        }
                        
                        // Handle channel conversion if needed
                        if channels == 1 {
                            // Duplicate mono to stereo
                            let mut stereo_data = Vec::with_capacity(pcm_data.len() * 2);
                            for chunk in pcm_data.chunks(2) {
                                stereo_data.extend_from_slice(chunk); // Left
                                stereo_data.extend_from_slice(chunk); // Right
                            }
                            let _ = audio_tx_clone.send(stereo_data);
                        } else {
                            let _ = audio_tx_clone.send(pcm_data);
                        }
                    },
                    |err| eprintln!("Audio input error: {}", err),
                    None,
                )?
            }
            _ => return Err(anyhow::anyhow!("Unsupported sample format: {:?}", config.sample_format())),
        };

        stream.play().context("Failed to start audio stream")?;
        
        // Keep the stream alive - it will be dropped when the function returns
        std::mem::forget(stream);
        
        Ok(())
    }

    fn create_wav_header(sample_rate: u32, channels: u16, data_size: u32) -> Vec<u8> {
        let mut header = Vec::with_capacity(44);
        
        // RIFF header
        header.extend_from_slice(b"RIFF");
        header.extend_from_slice(&(36 + data_size).to_le_bytes()); // File size - 8
        header.extend_from_slice(b"WAVE");
        
        // fmt chunk
        header.extend_from_slice(b"fmt ");
        header.extend_from_slice(&16u32.to_le_bytes()); // fmt chunk size
        header.extend_from_slice(&1u16.to_le_bytes());  // PCM format
        header.extend_from_slice(&channels.to_le_bytes()); // Number of channels
        header.extend_from_slice(&sample_rate.to_le_bytes()); // Sample rate
        
        let byte_rate = sample_rate * channels as u32 * 2; // 16-bit = 2 bytes per sample
        header.extend_from_slice(&byte_rate.to_le_bytes()); // Byte rate
        
        let block_align = channels * 2; // 16-bit = 2 bytes per sample
        header.extend_from_slice(&block_align.to_le_bytes()); // Block align
        header.extend_from_slice(&16u16.to_le_bytes()); // Bits per sample
        
        // data chunk
        header.extend_from_slice(b"data");
        header.extend_from_slice(&data_size.to_le_bytes()); // Data size
        
        header
    }

    async fn broadcast_file(&self, file_path: &str, speaker_name: &str) -> Result<()> {
        let device = self.find_device(speaker_name).await?;

        // Use random available port
        let server_port = 0u16;
        let (audio_tx, actual_port, server_handle) = self.create_streaming_server(server_port).await?;
        
        let audio_url = format!("http://{}:{}/stream.wav",
            local_ip_address::local_ip().unwrap_or_else(|_| "127.0.0.1".parse().unwrap()),
            actual_port);

        // Start FFmpeg and Chromecast connection in parallel
        println!("Starting file streaming for {}", file_path);
        let file_path_clone = file_path.to_string();
        let streaming_handle = tokio::task::spawn_blocking(move || {
            let mut ffmpeg = Command::new("ffmpeg")
                .args([
                    "-re",  // Read input at native frame rate (real-time)
                    "-i", &file_path_clone,
                    "-acodec", "pcm_s16le",  // 16-bit PCM
                    "-ar", "44100",
                    "-ac", "2",
                    "-f", "wav",
                    "-"
                ])
                .stdout(Stdio::piped())
                .stderr(Stdio::null())
                .spawn()
                .expect("Failed to start FFmpeg");

            let mut stdout = ffmpeg.stdout.take().expect("Failed to get FFmpeg stdout");
            let mut buffer = [0u8; 8192];
            let mut total_bytes = 0;

            loop {
                match stdout.read(&mut buffer) {
                    Ok(0) => break, // EOF
                    Ok(n) => {
                        total_bytes += n;
                        if audio_tx.send(buffer[..n].to_vec()).is_err() {
                            break; // Receiver dropped
                        }
                        
                    }
                    Err(_) => break,
                }
            }

            println!("FFmpeg finished, total bytes: {}", total_bytes);
            let _ = ffmpeg.wait();
        });

        // Connect to Chromecast immediately - HTTP streaming will handle buffering
        println!("Connecting to Chromecast...");
        self.cast_audio(&device, &audio_url).await?;

        println!("Streaming file {} to {} - audio should start immediately", file_path, device.name);

        // Wait for streaming to complete or timeout
        let _ = tokio::time::timeout(Duration::from_secs(300), streaming_handle).await;
        
        // Clean up
        server_handle.abort();
        println!("Finished streaming file");

        Ok(())
    }

    async fn broadcast_live(&self, speaker_name: &str) -> Result<()> {
        let device = self.find_device(speaker_name).await?;

        // Use random available port
        let server_port = 0u16;
        let (audio_tx, actual_port, server_handle) = self.create_streaming_server(server_port).await?;
        
        let audio_url = format!("http://{}:{}/stream.wav",
            local_ip_address::local_ip().unwrap_or_else(|_| "127.0.0.1".parse().unwrap()),
            actual_port);

        // Start native audio recording
        println!("Starting native audio capture...");
        self.start_audio_recording(audio_tx)
            .context("Failed to start audio recording")?;

        // Connect to Chromecast immediately - HTTP streaming will handle buffering
        println!("Connecting to Chromecast...");
        self.cast_audio(&device, &audio_url).await?;

        println!("Recording and streaming live audio to {} - audio should start immediately", device.name);
        println!("Press Ctrl+C to stop.");

        // Wait for interrupt signal
        tokio::signal::ctrl_c().await?;

        println!("\nStopping live stream...");

        // Clean up
        server_handle.abort();

        println!("Live streaming stopped");

        Ok(())
    }


    async fn start_web_interface(&self, port: u16) -> Result<()> {
        let websocket_tx = self.websocket_tx.clone();

        let websocket_route = warp::path("ws")
            .and(warp::ws())
            .map(move |ws: warp::ws::Ws| {
                let websocket_tx = websocket_tx.clone();
                ws.on_upgrade(move |websocket| async move {
                    handle_websocket_upgrade(websocket, websocket_tx).await;
                })
            });

        let cors = warp::cors()
            .allow_any_origin()
            .allow_headers(vec!["content-type"])
            .allow_methods(vec!["GET", "POST", "OPTIONS"]);

        let routes = websocket_route.with(cors);

        println!("WebSocket server starting on ws://localhost:{}/ws", port);
        warp::serve(routes)
            .run(([127, 0, 0, 1], port))
            .await;

        Ok(())
    }
}

async fn handle_websocket_upgrade(
    websocket: warp::ws::WebSocket,
    websocket_tx: broadcast::Sender<WebSocketMessage>,
) {
    let (mut ws_tx, mut ws_rx) = websocket.split();
    let mut broadcast_rx = websocket_tx.subscribe();

    // Handle incoming messages
    let ws_handler = tokio::spawn(async move {
        while let Some(result) = ws_rx.next().await {
            match result {
                Ok(msg) => {
                    if let Ok(text) = msg.to_str() {
                        if let Ok(ws_msg) = serde_json::from_str::<WebSocketMessage>(text) {
                            match ws_msg {
                                WebSocketMessage::DiscoverDevices => {
                                    let response = WebSocketMessage::DevicesFound {
                                        devices: vec![] // Simplified for now
                                    };
                                    let _ = websocket_tx.send(response);
                                }
                                _ => {
                                    let response = WebSocketMessage::Error {
                                        message: "Message type not yet implemented".to_string(),
                                    };
                                    let _ = websocket_tx.send(response);
                                }
                            }
                        }
                    }
                }
                Err(e) => {
                    eprintln!("WebSocket error: {}", e);
                    break;
                }
            }
        }
    });

    // Handle outgoing messages
    let broadcast_handler = tokio::spawn(async move {
        while let Ok(msg) = broadcast_rx.recv().await {
            if let Ok(json) = serde_json::to_string(&msg) {
                if ws_tx.send(warp::ws::Message::text(json)).await.is_err() {
                    break;
                }
            }
        }
    });

    // Wait for either handler to complete
    tokio::select! {
        _ = ws_handler => {},
        _ = broadcast_handler => {},
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    let args = Args::parse();
    let broadcaster = ChromecastBroadcaster::new();

    if args.list {
        let devices = broadcaster.discover_devices(args.force).await?;
        println!("Available Chromecast devices:");
        for device in devices {
            println!("  {} ({}:{})", device.name, device.ip, device.port);
        }
        return Ok(());
    }

    if args.web {
        broadcaster.start_web_interface(args.port).await?;
        return Ok(());
    }

    let speaker_name = args.speaker
        .or_else(|| std::env::var("CHROMECAST_SPEAKER").ok())
        .context("Speaker name required. Use -s option or set CHROMECAST_SPEAKER env var")?;

    if args.live {
        broadcaster.broadcast_live(&speaker_name).await?;
    } else if let Some(file_path) = args.file {
        broadcaster.broadcast_file(file_path.to_str().unwrap(), &speaker_name).await?;
    } else {
        // Check if stdin has data
        use std::io::IsTerminal;

        if io::stdin().is_terminal() {
            eprintln!("Error: No audio file specified. Use one of:");
            eprintln!("  chromecast-broadcast <audio_file> -s <speaker>");
            eprintln!("  chromecast-broadcast --live -s <speaker>");
            eprintln!("  echo 'audio data' | chromecast-broadcast -s <speaker>");
            return Ok(());
        }

        // Read from stdin
        let mut buffer = Vec::new();
        io::stdin().read_to_end(&mut buffer)?;

        if buffer.is_empty() {
            eprintln!("Error: No data received from stdin");
            return Ok(());
        }

        // Write stdin data to a temporary file
        let temp_file = format!("/tmp/stdin_cast_{}", uuid::Uuid::new_v4());
        tokio::fs::write(&temp_file, &buffer).await?;

        // Broadcast the file (it will be converted to MP3 if needed)
        broadcaster.broadcast_file(&temp_file, &speaker_name).await?;

        let _ = tokio::fs::remove_file(&temp_file).await;
    }

    Ok(())
}