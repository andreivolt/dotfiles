#!/usr/bin/env uv run -qs --with telethon,platformdirs
import os
import json
import argparse
import asyncio
from datetime import datetime
from telethon import TelegramClient
from telethon.tl.types import PeerChannel, Channel, Chat, User
from platformdirs import user_state_dir

def list_dialogs(api_id, api_hash, json_output=False):
    client = TelegramClient(os.path.join(user_state_dir(), 'telethon'), api_id, api_hash)

    async def main():
        await client.start()
        dialogs = await client.get_dialogs()

        dialogs_data = []

        for dialog in dialogs:
            entity = dialog.entity

            if isinstance(entity, Channel):
                entity_type = "channel" if entity.broadcast else "supergroup"
            elif isinstance(entity, Chat):
                entity_type = "group"
            elif isinstance(entity, User):
                entity_type = "user"
            else:
                entity_type = "unknown"

            # Handle deleted accounts properly
            # Telegram typically shows "Deleted Account" for deleted users
            if dialog.name == "Deleted Account" or not dialog.name:
                name = "Deleted Account"
            else:
                name = dialog.name

            # Get username if available
            username = getattr(entity, 'username', None)
            username_str = f"@{username}" if username else ""

            if json_output:
                dialogs_data.append({
                    "chat_id": entity.id,
                    "name": name,
                    "username": username,
                    "type": entity_type,
                    "unread_count": dialog.unread_count,
                    "last_message_date": dialog.date.isoformat() if dialog.date else None,
                })
            else:
                # Tab-separated format for easy parsing with fields in consistent positions
                # Format: {chat_id}\t{name}\t{type}\t{username}
                # This makes it easy to split on \t to get field values
                print(f"{entity.id}\t{name}\t{entity_type}\t{username_str}")

        if json_output:
            print(json.dumps(dialogs_data, indent=2))

    with client:
        client.loop.run_until_complete(main())

def format_message(message, sender, format_type="text"):
    """Format a message according to the specified format"""
    if sender:
        if getattr(sender, 'username', None):
            sender_name = f"@{sender.username}"
        else:
            sender_name = f"{sender.first_name or ''} {sender.last_name or ''}".strip()
        sender_id = sender.id
        is_bot = getattr(sender, 'bot', False)
    else:
        sender_name = "Unknown"
        sender_id = None
        is_bot = False

    timestamp = message.date.isoformat() if message.date else None
    msg_id = message.id
    content = message.text or ""
    has_media = message.media is not None

    if format_type == "json":
        return {
            "id": msg_id,
            "timestamp": timestamp,
            "sender": {
                "name": sender_name,
                "id": sender_id,
                "is_bot": is_bot
            },
            "content": content,
            "has_media": has_media
        }
    elif format_type == "markdown":
        media_indicator = " [MEDIA]" if has_media else ""
        return f"### Message {msg_id}\n**From:** {sender_name} (ID: {sender_id})\n**Time:** {timestamp}\n**Bot:** {'Yes' if is_bot else 'No'}\n\n{content}{media_indicator}\n\n---\n"
    else:  # text
        media_indicator = " [MEDIA]" if has_media else ""
        return f"[{timestamp}] {sender_name}: {content}{media_indicator}"

def fetch_messages(api_id, api_hash, channel_input, num_messages=None, format_type="text", batch_size=200, reverse_order=False, search_query=None, parallel=5, from_date=None, to_date=None):
    client = TelegramClient(os.path.join(user_state_dir(), 'telethon'), api_id, api_hash)

    async def main():
        await client.start()
        # If an integer was provided, assume it's a channel/chat ID.
        if isinstance(channel_input, int):
            await client.get_dialogs()  # Populate the cache with entities.
            try:
                channel = await client.get_entity(PeerChannel(channel_input))
            except:
                # If not a channel, try direct lookup by ID
                channel = await client.get_entity(channel_input)
        else:
            channel = await client.get_entity(channel_input)

        # For JSON format, we'll collect all messages in a list
        all_messages = [] if format_type == "json" else None

        if num_messages is None:
            offset_id = 0
            total_messages = 0

            # If streaming in reverse chronological order is requested (newest first)
            if reverse_order and format_type != "json":
                search_msg = f" (searching for '{search_query}')" if search_query else ""
                print(f"Streaming messages (newest first){search_msg}...")

                # Direct streaming output as messages are retrieved
                while True:
                    # Build parameters for client.get_messages
                    kwargs = {
                        'limit': batch_size,
                        'offset_id': offset_id
                    }

                    # Add date filters if provided
                    if from_date:
                        kwargs['offset_date'] = from_date

                    # Add search query if provided
                    if search_query:
                        kwargs['search'] = search_query

                    messages = await client.get_messages(channel, **kwargs)

                    if not messages:
                        break

                    batch_count = 0
                    for message in messages:
                        # Apply to_date filter if provided
                        if to_date and message.date > to_date:
                            continue

                        # Skip messages earlier than from_date
                        if from_date and message.date < from_date:
                            continue

                        if not message.text and not message.media:
                            continue  # Skip empty messages

                        sender = message.sender or await message.get_sender()
                        print(format_message(message, sender, format_type))
                        batch_count += 1

                    total_messages += batch_count
                    if messages:
                        offset_id = messages[-1].id

                    print(f"Retrieved {total_messages} messages...", end="\r", flush=True)

                print(f"\nExport complete. Total: {total_messages} messages.")

            # For chronological order or JSON output, we need to collect all messages first
            else:
                all_retrieved_messages = []

                # First pass: collect all messages in parallel
                search_msg = f" (searching for '{search_query}')" if search_query else ""
                print(f"Retrieving messages{search_msg} using parallel fetching...")

                # Function to fetch a chunk of messages
                async def fetch_chunk(chunk_offset_id):
                    try:
                        # Build parameters for client.get_messages
                        kwargs = {
                            'limit': batch_size,
                            'offset_id': chunk_offset_id
                        }

                        # Add date filters if provided
                        if from_date:
                            kwargs['offset_date'] = from_date

                        # Add search query if provided
                        if search_query:
                            kwargs['search'] = search_query

                        chunk = await client.get_messages(channel, **kwargs)

                        chunk_results = []
                        for message in chunk:
                            # Apply to_date filter if provided
                            if to_date and message.date > to_date:
                                continue

                            # Skip messages earlier than from_date
                            if from_date and message.date < from_date:
                                continue

                            if not message.text and not message.media:
                                continue  # Skip empty messages

                            sender = message.sender or await message.get_sender()
                            chunk_results.append((message, sender))

                        # Find the last message ID for next chunk
                        next_offset = 0
                        if chunk:
                            next_offset = chunk[-1].id

                        return chunk_results, next_offset
                    except Exception as e:
                        print(f"\nError fetching chunk: {e}")
                        return [], 0

                # Number of parallel chunks to fetch
                parallel_chunks = parallel

                # Start with initial offset
                offset_ids = [offset_id]
                total_chunks_fetched = 0

                # Fetch messages in parallel chunks
                while offset_ids:
                    # Prepare tasks for this batch of chunks
                    tasks = []
                    for chunk_offset in offset_ids[:parallel_chunks]:
                        tasks.append(fetch_chunk(chunk_offset))

                    # Wait for all chunks to complete
                    results = await asyncio.gather(*tasks)

                    # Process results and prepare next batch
                    new_offset_ids = []
                    for chunk, next_offset in results:
                        if chunk:
                            all_retrieved_messages.extend(chunk)
                            if next_offset > 0:
                                new_offset_ids.append(next_offset)

                    # Update for next iteration
                    offset_ids = new_offset_ids
                    total_chunks_fetched += len(tasks)
                    total_messages = len(all_retrieved_messages)

                    print(f"Retrieved {total_messages} messages from {total_chunks_fetched} chunks...", end="\r", flush=True)

                # If chronological order (oldest first), reverse the list
                if not reverse_order:
                    print(f"\nReordering messages (oldest first)...", end="\r", flush=True)
                    all_retrieved_messages.reverse()

                # Output the messages
                print("\nExporting messages...")
                for idx, (message, sender) in enumerate(all_retrieved_messages):
                    if format_type == "json":
                        all_messages.append(format_message(message, sender, "json"))
                    else:
                        print(format_message(message, sender, format_type))

                    # Show progress periodically
                    if idx % 100 == 0 and format_type != "json":
                        print(f"Exported {idx}/{total_messages} messages...", end="\r", flush=True)

                if format_type == "json":
                    # Output JSON at the end for complete dataset
                    result = {
                        "chat": {
                            "chat_id": channel.id,
                            "name": getattr(channel, 'title', None) or getattr(channel, 'username', None) or "",
                            "type": type(channel).__name__
                        },
                        "export_date": datetime.now().isoformat(),
                        "messages": all_messages
                    }
                    print(json.dumps(result, indent=2))
                else:
                    print(f"\nExport complete. Total: {total_messages} messages.")
        else:
            # Get limited number of messages, newest first
            # Build parameters for client.get_messages
            kwargs = {
                'limit': num_messages
            }

            # Add date filters if provided
            if from_date:
                kwargs['offset_date'] = from_date

            # Add search query if provided
            if search_query:
                kwargs['search'] = search_query

            messages = await client.get_messages(channel, **kwargs)

            # Apply to_date filter manually for the upper bound
            if to_date:
                messages = [msg for msg in messages if msg.date <= to_date]

            # For streaming in reverse chronological order
            if reverse_order and format_type != "json":
                search_msg = f" (searching for '{search_query}')" if search_query else ""
                print(f"Streaming up to {num_messages} messages (newest first){search_msg}...")
                for message in messages:
                    if not message.text and not message.media:
                        continue

                    sender = message.sender or await message.get_sender()
                    print(format_message(message, sender, format_type))

                print(f"\nExport complete. Total: {len(messages)} messages.")
            else:
                # Prepare for chronological display (oldest first)
                all_retrieved_messages = []

                # First, collect messages with their senders
                for message in messages:
                    if not message.text and not message.media:
                        continue

                    sender = message.sender or await message.get_sender()
                    all_retrieved_messages.append((message, sender))

                # Reverse to get oldest first if chronological order is requested
                if not reverse_order:
                    all_retrieved_messages.reverse()

                # Output the messages
                if format_type == "json":
                    for message, sender in all_retrieved_messages:
                        all_messages.append(format_message(message, sender, "json"))

                    result = {
                        "chat": {
                            "chat_id": channel.id,
                            "name": getattr(channel, 'title', None) or getattr(channel, 'username', None) or "",
                            "type": type(channel).__name__
                        },
                        "export_date": datetime.now().isoformat(),
                        "messages": all_messages
                    }
                    print(json.dumps(result, indent=2))
                else:
                    for message, sender in all_retrieved_messages:
                        print(format_message(message, sender, format_type))

                    print(f"\nExport complete. Total: {len(all_retrieved_messages)} messages.")

    with client:
        client.loop.run_until_complete(main())

def main():
    parser = argparse.ArgumentParser(
        description="Telegram conversation and message export tool"
    )

    commands = parser.add_subparsers(dest="command", help="Command to execute")

    # Add usage examples to help text
    # No examples in epilog
    parser.epilog = ""
    parser.formatter_class = argparse.RawDescriptionHelpFormatter

    # List command
    list_cmd = commands.add_parser("list", help="List all available conversations")
    list_cmd.add_argument(
        "--json", "-j",
        action="store_true",
        help="Output in JSON format"
    )

    # Export command
    export_cmd = commands.add_parser("export", help="Export messages from a conversation")
    export_cmd.add_argument(
        "identifier",
        help="Chat ID or username to export messages from"
    )
    export_cmd.add_argument(
        "--limit", "-l",
        type=int,
        default=None,
        help="Number of recent messages to export (default: all)"
    )
    export_cmd.add_argument(
        "--format", "-f",
        choices=["text", "json", "markdown"],
        default="text",
        help="Output format (default: text)"
    )
    export_cmd.add_argument(
        "--reverse", "-r",
        action="store_true",
        help="Output in reverse chronological order (newest first). Enables streaming output."
    )
    export_cmd.add_argument(
        "--search", "-s",
        type=str,
        help="Search for messages containing the specified text"
    )
    export_cmd.add_argument(
        "--parallel", "-p",
        type=int,
        default=5,
        help="Number of parallel fetching tasks (default: 5, higher values may improve speed but use more resources)"
    )
    export_cmd.add_argument(
        "--from-date",
        type=str,
        help="Filter messages from this date (format: YYYY-MM-DD)"
    )
    export_cmd.add_argument(
        "--to-date",
        type=str,
        help="Filter messages up to this date (format: YYYY-MM-DD)"
    )

    # For backward compatibility
    parser.add_argument(
        "--list",
        action="store_true",
        help=argparse.SUPPRESS
    )
    parser.add_argument(
        "--channel",
        help=argparse.SUPPRESS
    )
    parser.add_argument(
        "--num",
        type=int,
        default=None,
        help=argparse.SUPPRESS
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help=argparse.SUPPRESS
    )

    args = parser.parse_args()

    API_ID = os.getenv('TELEGRAM_API_ID')
    API_HASH = os.getenv('TELEGRAM_API_HASH')
    if not API_ID or not API_HASH:
        parser.error("Set TELEGRAM_API_ID and TELEGRAM_API_HASH environment variables.")

    # Handle new command structure
    if args.command == "list":
        list_dialogs(API_ID, API_HASH, args.json)
    elif args.command == "export":
        try:
            channel_input = int(args.identifier)
        except ValueError:
            channel_input = args.identifier

        # Parse date strings to datetime objects if provided
        from_date = None
        to_date = None
        if args.from_date:
            try:
                from_date = datetime.strptime(args.from_date, "%Y-%m-%d")
            except ValueError:
                parser.error("Invalid from-date format. Use YYYY-MM-DD")

        if args.to_date:
            try:
                to_date = datetime.strptime(args.to_date, "%Y-%m-%d")
                # Set time to end of day (23:59:59)
                to_date = to_date.replace(hour=23, minute=59, second=59)
            except ValueError:
                parser.error("Invalid to-date format. Use YYYY-MM-DD")

        fetch_messages(API_ID, API_HASH, channel_input, args.limit, args.format,
                       reverse_order=args.reverse, search_query=args.search,
                       parallel=args.parallel, from_date=from_date, to_date=to_date)

    # Handle legacy arguments
    elif args.list:
        list_dialogs(API_ID, API_HASH, args.json)
    elif args.channel:
        try:
            channel_input = int(args.channel)
        except ValueError:
            channel_input = args.channel

        format_type = "json" if args.json else "text"
        fetch_messages(API_ID, API_HASH, channel_input, args.num, format_type)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
