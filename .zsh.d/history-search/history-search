#!/usr/bin/env rust-script
//! ```cargo
//! [dependencies]
//! clap = { version = "4.0", features = ["derive"] }
//! chrono = { version = "0.4", features = ["serde"] }
//! regex = "1.0"
//! serde = { version = "1.0", features = ["derive"] }
//! bincode = "1.3"
//! timeago = "0.4"
//! ```

use chrono::{Local, TimeZone};
use clap::Parser;
use regex::Regex;
use serde::{Deserialize, Serialize};
use std::collections::HashSet;
use std::env;
use std::fs;
use std::io::{self, BufRead, BufReader, Write};
use std::path::{Path, PathBuf};
use std::process::{Command, Stdio};
use std::time::SystemTime;
use timeago::Formatter;

const EXTENDED_HISTORY_REGEX: &str = r"^: (\d+):\d+;(.*)$";

#[derive(Parser)]
#[command(name = "history-search")]
#[command(about = "Fuzzy search through zsh history with dates")]
struct Args {
    #[arg(short, long, help = "History file path")]
    file: Option<PathBuf>,

    #[arg(short, long, help = "Maximum number of entries to show")]
    limit: Option<usize>,

    #[arg(short, long, help = "Show relative dates (e.g., '2 hours ago')")]
    relative: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct HistoryEntry {
    timestamp: Option<i64>,
    command: String,
}

#[derive(Serialize, Deserialize)]
struct HistoryCache {
    entries: Vec<HistoryEntry>,
    last_modified: SystemTime,
    file_size: u64,
    line_count: usize,
}

fn format_relative_time(timestamp: i64) -> String {
    let formatter = Formatter::new();
    let now = Local::now();
    let then = Local.timestamp_opt(timestamp, 0).single().unwrap_or(now);
    formatter.convert_chrono(then, now)
}

fn main() {
    let mut args = Args::parse();
    
    // Check if relative dates should be enabled by default via environment variable
    if !args.relative && env::var("ZSH_HISTORY_RELATIVE_DATES").is_ok() {
        args.relative = true;
    }

    let history_file = args.file.unwrap_or_else(|| {
        env::var("HISTFILE")
            .map(PathBuf::from)
            .unwrap_or_else(|_| {
                let home = env::var("HOME").expect("HOME environment variable not set");
                let local_state_path = PathBuf::from(&home).join(".local/state/zsh/history");
                if local_state_path.exists() {
                    local_state_path
                } else {
                    PathBuf::from(home).join(".zsh_history")
                }
            })
    });

    let entries = match get_or_update_cache(&history_file) {
        Ok(entries) => entries,
        Err(e) => {
            eprintln!("Error reading history file: {}", e);
            return;
        }
    };

    if entries.is_empty() {
        eprintln!("No history entries found");
        return;
    }

    // Collect unique entries maintaining chronological order (newest first)
    let mut seen_commands = HashSet::new();
    let unique_entries: Vec<_> = entries
        .iter()
        .rev()
        .filter(|entry| seen_commands.insert(entry.command.clone()))
        .collect();

    // Format the display entries
    let display_entries: Vec<String> = unique_entries
        .into_iter()
        .take(args.limit.unwrap_or(usize::MAX))
        .map(|entry| {
            entry.timestamp
                .and_then(|timestamp| Local.timestamp_opt(timestamp, 0).single())
                .map(|dt| {
                    let formatted_date = if args.relative {
                        format!("{:>15}", format_relative_time(dt.timestamp()))
                    } else {
                        dt.format("%Y-%m-%d %H:%M").to_string()
                    };
                    format!("\x1b[90m{}\x1b[0m {}", formatted_date, entry.command)
                })
                .unwrap_or_else(|| entry.command.clone())
        })
        .collect();

    // Keep newest entries first (don't reverse)

    // Use fzf with just the history-specific options, inherit FZF_DEFAULT_OPTS from environment
    let mut fzf = Command::new("fzf")
        .arg("--nth=2..")
        .arg("--no-multi")
        .arg("--scheme=history")
        .arg("--bind=ctrl-r:toggle-sort")
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .spawn()
        .expect("Failed to start fzf");

    // Write entries to fzf
    if let Some(stdin) = fzf.stdin.as_mut() {
        for entry in &display_entries {
            writeln!(stdin, "{}", entry).unwrap();
        }
    }

    let output = fzf.wait_with_output().expect("Failed to read fzf output");

    if output.status.success() {
        let selected_line = String::from_utf8_lossy(&output.stdout).trim().to_string();
        // Extract just the command part (skip the date prefix)
        let command = if let Some(space_pos) = selected_line.find(' ') {
            &selected_line[space_pos + 1..]
        } else {
            &selected_line
        };
        println!("{}", command);
    }
}

fn get_cache_path() -> PathBuf {
    let cache_dir = env::var("XDG_CACHE_HOME")
        .unwrap_or_else(|_| format!("{}/.cache", env::var("HOME").unwrap()));
    PathBuf::from(cache_dir).join("zsh-history-search.cache")
}

fn load_cache() -> Option<HistoryCache> {
    let cache_path = get_cache_path();
    if let Ok(data) = fs::read(&cache_path) {
        bincode::deserialize(&data).ok()
    } else {
        None
    }
}

fn save_cache(cache: &HistoryCache) -> io::Result<()> {
    let cache_path = get_cache_path();
    if let Some(parent) = cache_path.parent() {
        fs::create_dir_all(parent)?;
    }
    let encoded = bincode::serialize(cache).map_err(|e| {
        io::Error::new(io::ErrorKind::Other, format!("Serialization error: {}", e))
    })?;
    fs::write(&cache_path, encoded)
}

fn count_lines(path: &Path) -> io::Result<usize> {
    let file = fs::File::open(path)?;
    let reader = BufReader::new(file);
    Ok(reader.lines().count())
}

fn parse_lines_from_offset(path: &Path, start_line: usize) -> io::Result<Vec<HistoryEntry>> {
    let contents = fs::read(path)?;
    let content_str = String::from_utf8_lossy(&contents);

    let extended_re = Regex::new(EXTENDED_HISTORY_REGEX)
        .expect("Invalid regex pattern");

    let entries = content_str
        .lines()
        .enumerate()
        .skip(start_line)
        .filter_map(|(_, line)| {
            if line.trim().is_empty() {
                return None;
            }

            if let Some(caps) = extended_re.captures(line) {
                let timestamp = caps[1].parse().unwrap_or(0);
                Some(HistoryEntry {
                    timestamp: Some(timestamp),
                    command: caps[2].to_string(),
                })
            } else {
                Some(HistoryEntry {
                    timestamp: None,
                    command: line.to_string(),
                })
            }
        })
        .collect();

    Ok(entries)
}

fn get_or_update_cache(history_file: &Path) -> io::Result<Vec<HistoryEntry>> {
    let metadata = fs::metadata(history_file)?;
    let current_modified = metadata.modified()?;
    let current_size = metadata.len();
    let current_line_count = count_lines(history_file)?;

    if let Some(mut cache) = load_cache() {
        // Check if we can use incremental update
        if cache.last_modified <= current_modified &&
           cache.file_size <= current_size &&
           cache.line_count <= current_line_count {

            // Only parse new lines
            let new_entries = parse_lines_from_offset(history_file, cache.line_count)?;
            cache.entries.extend(new_entries);
            cache.last_modified = current_modified;
            cache.file_size = current_size;
            cache.line_count = current_line_count;

            // Save updated cache
            let _ = save_cache(&cache);
            return Ok(cache.entries);
        }
    }

    // Full reparse needed
    let entries = parse_lines_from_offset(history_file, 0)?;
    let cache = HistoryCache {
        entries: entries.clone(),
        last_modified: current_modified,
        file_size: current_size,
        line_count: current_line_count,
    };

    let _ = save_cache(&cache);
    Ok(entries)
}
